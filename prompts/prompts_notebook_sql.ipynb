{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e06e51d3-37d9-4d14-a76e-c57bc2bb1c0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = \" You are a helpful assistant. For each question use unexecutable code to determine the answer. Do not capture unterminated strings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15cea277-9b4e-40a3-823a-4b41fc4f6b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# put reasoning above everything else. Explore Dspy \n",
    "sql_prompt_dict = {\n",
    "  \"prompt_instructions_1\": \"\"\" \n",
    "  Check if the provided context has any code snippet which creates a table/view called workloads and get shcema of workloads\n",
    "  Return the result in json format: \n",
    "  {\n",
    "    score: 15 if any code snippet below creates a table/view and displays its schema, 7.5 if it creates a table/view but does not display its schema,  0 if no code snippet creates a table/view,\n",
    "\n",
    "    code_snippet: provide the code snippet which creates a table/view and displays its schema encapsulated as a string,\n",
    "\n",
    "    reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "  }\n",
    "  Return result in the above mentioned format only. \n",
    "  \"\"\",\n",
    "\n",
    "  \"prompt_instructions_2\": \"\"\" \n",
    "  Check if the provided context has any code snippet which return a distinct list of workspaceID. \n",
    "    Return the result in json format :  \n",
    "    {\n",
    "        score: 15 if any code snippet below return a distinct list of workspaceID, 0 if no code snippet returns a list of distinct workspace id,\n",
    "    \n",
    "        code_snippet: provide the code snippet which returns a distinct list of workspace id  encapsulated as a string,\n",
    "\n",
    "        reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "    }\n",
    "    Return result in the above mentioned format only.\n",
    "  \"\"\",\n",
    "\n",
    "  \"prompt_instructions_3\": \"\"\" \n",
    "  Check if the provided context has any code snippet which returns the  number of unique clusters. \n",
    "    Return the result in json format : \n",
    "    {\n",
    "      score: 15 if any code snippet below returns the  number of unique clusters, 0 if no code snippet returns the number of unique clusters,\n",
    "\n",
    "      code_snippet: provide the code snippet which returns the  number of unique clusters encapsulated as a string,\n",
    "\n",
    "      reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "    }\n",
    "    Return result in the above mentioned format only. \n",
    "  \"\"\",\n",
    "\n",
    "  \"prompt_instructions_4\": \"\"\" \n",
    "  Check if the provided context has any code snippet which returns the  workload hours each day for the workspace id in ordered fashion. \n",
    "    Return the result in json format : \n",
    "    {\n",
    "      score: 15 if any code snippet below returns the  workload hours each day for the workspace id in ordered fashion, 12 points if any code snippet below returns workload hours each day for the workspace id but the order is missing, , 0 if no code snippet returns workload hours each day for the workspace id,\n",
    "\n",
    "      code_snippet: provide the code snippet which returns the  workload hours each day for the workspace id encapsulated as a string,\n",
    "\n",
    "      reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "    }\n",
    "    Return result in the above mentioned format only. \n",
    "  \"\"\",\n",
    "\n",
    "  \"prompt_instructions_5\": \"\"\" \n",
    "  Check if the provided context has any code snippet which returns interactive node hours per day on the different Spark versions over time. \n",
    "    Return the result in json format : \n",
    "    {\n",
    "      score: 15 if any code snippet below returns interactive node hours per day on the different Spark versions over time, 0 if no code snippet returns interactive node hours per day on the different Spark versions over time,\n",
    "\n",
    "      code_snippet: provide the code snippet which returns interactive node hours per day on the different Spark versions over time encapsulated as a string,\n",
    "\n",
    "      reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "    }\n",
    "    Return result in the above mentioned format only. \n",
    "  \"\"\",\n",
    "\n",
    "  \"prompt_instructions_6\": \"\"\" \n",
    "  Check if the provided context has any code snippet which returns top two most recently shipped (shipDate) Line Items per Part using window function \n",
    "    Return the result in json format : \n",
    "    {\n",
    "      score: 25 if any code snippet below returns top two most recently shipped (shipDate) Line Items per Part using window function, 20  if any code snippet below returns top two most recently shipped (shipDate) Line Items per Part using subquery, 10 if any code snippet below returns top two most recently shipped (shipDate) Line Items per Part but groups by the key only, 0 if no code snippet returns top two most recently shipped (shipDate) Line Items per Part,\n",
    "\n",
    "      code_snippet: provide the code snippet which returns top two most recently shipped (shipDate) Line Items per Part using window function encapsulated as a string,\n",
    "\n",
    "      reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "    }\n",
    "    Return result in the above mentioned format only.\n",
    "  \"\"\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53357bac-6824-4b2b-89c0-aba5fb3f6ad8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optimization_prompt_dict = {\n",
    "\n",
    "  \"prompt_instructions_1\": \"\"\" \n",
    "      Check if in the provided context shuffle partitions or partitions have been set as 1 \n",
    "      Return the result in json format described below:\n",
    "\n",
    "      {\n",
    "        question: Does extracted code snippet has shuffle partitions or partitions set as 1 or 4\n",
    "\n",
    "        score: 1 if the extracted code snippet has shuffle partitions or partitions set as 1, 0 otherwise\n",
    "\n",
    "        code_snippet: provide the code snippet in which paritions has been set as 1 cast as string. Provide complete snippet of code/query\n",
    "\n",
    "        reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "      }\n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\",\n",
    "\n",
    "  \"prompt_instructions_2\": \"\"\" \n",
    "      Check if udf function fetch was called directly instead of using RestClient class and initiating an object for every call\n",
    "      Return the result in json format:\n",
    "\n",
    "      {\n",
    "        question: Does udf function fetch was called directly instead of using RestClient class and initiating an object for every call\n",
    "\n",
    "        score: 1 udf function fetch was called directly instead of using RestClient class and initiating an object for every call, 0 otherwise\n",
    "\n",
    "        code_snippet: provide the code snippet in which udf function fetch was called directly cast as string. Provide complete snippet of code/query\n",
    "\n",
    "        reasoning: provide your explanation for providing the above score  less than 50 words \n",
    "      }\n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\",\n",
    "\n",
    "    \"prompt_instructions_3\":  \"\"\" \n",
    "      Check if function fetchUDF is being called directly against citiesDF\n",
    "      Return the result in json format:\n",
    "\n",
    "      {\n",
    "        question: Does function fetchUDF is being called directly against citiesDF\n",
    "\n",
    "        score: 1 if function fetchUDF is being called directly against citiesDF, 0 otherwise\n",
    "\n",
    "        code_snippet: provide the code snippet in which function fetchUDF is being called directly against citiesDF cast as string. Provide complete snippet of code/query\n",
    "\n",
    "        reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "      } \n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\",\n",
    "\n",
    "      \"prompt_instructions_4\":  \"\"\" \n",
    "        Check if broadcasting join is used for citiesDF\n",
    "        Return the result in json format:\n",
    "\n",
    "        {\n",
    "          question: Does broadcasting join is used for citiesDF\n",
    "\n",
    "          score: 1 if broadcasting join is used for citiesDF, 0 otherwise\n",
    "\n",
    "          code_snippet: provide the code snippet in which broadcasting join is used for citiesDF cast as string. Provide complete snippet of code/query\n",
    "\n",
    "          reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "      } \n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\",\n",
    "\n",
    "      \"prompt_instructions_5\":  \"\"\" \n",
    "        Check if '.repartition(sc.defaultParallelism)' is removed\n",
    "        Return the result in json format:\n",
    "\n",
    "        {\n",
    "          question: Does repartition(sc.defaultParallelism) is removed or repartition('zip_code') is used\n",
    "\n",
    "          score: 1 if repartition(sc.defaultParallelism) or repartition('zip_code') is not used, 0 otherwise\n",
    "\n",
    "          code_snippet: provide the code snippet cast as string. Provide complete snippet of code/query\n",
    "\n",
    "          reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "      } \n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\",\n",
    "\n",
    "      \"prompt_instructions_6\":  \"\"\" \n",
    "        Check if filter on 'state_abv' is applied first before calling UDF\n",
    "        Return the result in json format:\n",
    "\n",
    "        {\n",
    "          question: Does filter on state_abv is applied first before calling UDF\n",
    "\n",
    "          score: 1 if filter on state_abv is applied first before calling UDF, 0 otherwise\n",
    "\n",
    "          code_snippet: provide the code snippet where filter on state_abv is applied first before calling UDF cast as string. Provide complete snippet of code/query\n",
    "\n",
    "          reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "      } \n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\",\n",
    "\n",
    "      \"prompt_instructions_7\":  \"\"\" \n",
    "        Check if selected code will produce 1 job with 2 stages\n",
    "        Return the result in json format:\n",
    "\n",
    "        {\n",
    "          question: Does selected code will produce 1 job with 2 stages\n",
    "\n",
    "          score: 1 if selected code will produce 1 job with 2 stages, 0 otherwise\n",
    "\n",
    "          code_snippet: provide the code snippet where selected code will produce 1 job with 2 stages cast as string\n",
    "          \n",
    "          reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "      } \n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\",\n",
    "\n",
    "      \"prompt_instructions_8\":   \"\"\" \n",
    "        Check if schema was specified in selected code\n",
    "        Return the result in json format:\n",
    "\n",
    "        {\n",
    "          question: Was schema specified in selected code\n",
    "\n",
    "          score: 1 if schema was specified in selected code, 0 otherwise\n",
    "\n",
    "          code_snippet: provide the code snippet schema was specified in selected code cast as string. Provide complete snippet of code/query\n",
    "\n",
    "          reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "      } \n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\"\n",
    "\n",
    "    #   \"prompt_instructions_9\":   \"\"\" \n",
    "    #     Extract the code snippet for finalDF. Execute the code snippet and check its runtime.\n",
    "    #     Return the result in json format:\n",
    "\n",
    "    #     {\n",
    "    #       question: Did query run in less than 3 minutes\n",
    "\n",
    "    #       score: 1 if finalDF query executes in less than 3 minutes, 0 otherwise\n",
    "\n",
    "    #       code_snippet:  Provide complete snippet of finalDF\n",
    "\n",
    "    #       reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "    #   } \n",
    "    #  Returned result should only contain json and no additional comments/explanation \n",
    "    #   \"\"\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c92f1a2b-ee75-4a40-bfdf-1edc43a3d3ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coding_prompt_dict = {\n",
    "    \"prompt_instructions_1\":  \"\"\" \n",
    "      Isolate the code for class DataGenerator and 15 separate out code for 15 methods/fucntions defined within the class. For each method check if the comment section has \n",
    "        1. comment has specified input parameters \n",
    "        2. comment has specified output parameters \n",
    "        3. comment has explained what this function does \n",
    "        4. comment has standard coding style \n",
    "      \n",
    "      For scala code use https://docs.scala-lang.org/style/scaladoc.html docs for comparison \n",
    "      For python code use https://www.python.org/dev/peps/pep-0257/ docs for comparison\n",
    "\n",
    "      {\n",
    "        question: How many of the 15 code snippets follow comment standards. \n",
    "\n",
    "        score: 15 if all sections follow commenting standards. for every section that does not follow commenting standard deduct 1 point, \n",
    "\n",
    "        code_snippet: provide method signature with comment where 4 checks defined above have not been followed cast as string, \n",
    "\n",
    "        reasoning: provide your explanation for providing the above score in less than 50 words \n",
    "      }\n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\"\n",
    "    \"prompt_instructions_2\":  \"\"\" \n",
    "      For scala code use https://docs.scala-lang.org/style/scaladoc.html docs as coding style reference\n",
    "      For python code use https://www.python.org/dev/peps/pep-0257/ docs as coding style reference\n",
    "\n",
    "      Many data manipulation tasks require the identification and handling of skewed data. This is particularly important for ensuring optimal Spark jobs. In this section, examine the data set that is generated and write a function that will determine the skewness of each column. The only distribution types that are required to be detected are: Evenly Distributed, Left Tailed, Right Tailed. The return type of this function should be a Dictionary of (ColumnName -> Distribution Type)\n",
    "      \n",
    "\n",
    "      {\n",
    "        question: Implement a function for Data Normalcy and Filtering \n",
    "\n",
    "        score: The total score for this question is 25 points. \n",
    "        Locate the function for determining the distribution type. Grading rubric is as follows:\n",
    "          - 15 points if the function is implemented correctly for determining all 3 distribution types mentioned above.\n",
    "          - 10 points if the function is used to determine the distribution type correctly for \"value2_std\", \"value3_std\", \"value4_std\" and \"value6_std\"\n",
    "          - deduct 5 points if the respective Python/Scala coding style is not used for ducumenting the function.\n",
    "          - deduct 5 points for Inferred skew (and not the exact calculation) from spark functions (that sampling with Spark's function will always give the same answer, but an actual calculation will vary as the generated counts increase for one of the distributions.)\n",
    "\n",
    "        code_snippet: provide the function for determining the distribution type cast as string,\n",
    "\n",
    "        reasoning: provide your explanation for providing the above score in less than 1000 words. Provide an explantion for deducting points \n",
    "      }\n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\"\n",
    "    \"prompt_instructions_3\":  \"\"\" \n",
    "      In order to validate that the function that you have written for identifying distribution type performs as intended, write a simple test that could be placed in a unit testing framework.\n",
    "      - Demonstrate that the test passes while validating proper classification of at maximum 1 type of distribution\n",
    "      -Demonstate the test failing at classifying correctly, but ensure that the application continues to run (handle the exception and report the failure to stdout)\n",
    "      \n",
    "\n",
    "      {\n",
    "        question: Implement testing for the function that determines the distribution type.\n",
    "\n",
    "        score: The total score for this question is 15 points. \n",
    "        Locate the test cases that have been implemented for the function for determining the distribution type. Grading rubric is as follows:\n",
    "          - 9 points if the code demonstrates that the test passes while validating proper classification of at maximum 1 type of distribution.\n",
    "          - 6 points if the code demonstrates the test failing at classifying correctly, but ensure that the application continues to run. i.e. exception handling.\n",
    "\n",
    "        code_snippet: provide the code that tests the function for determining the distribution type cast as string\n",
    "\n",
    "        reasoning: provide your explanation for providing the above score in less than 1000 words. Provide an explantion for deducting points\n",
    "      }\n",
    "     Returned result should only contain json and no additional comments/explanation \n",
    "      \"\"\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "prompts_notebook_sql",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
