{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a82f190-dbec-428c-b8a8-991f921373dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install nbformat databricks-sdk[openai]==0.38.0 dspy --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac10c02-5a99-4d1a-846a-34df84391e03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a77fb14-401f-4417-a417-4f7330dde64b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM('databricks/databricks-meta-llama-3-3-70b-instruct')\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "555bb1a0-41dd-4982-82f8-08828d0c0dd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../prompts/ml_prompts_with_DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f912084d-5ea3-4b25-9e54-ba527a5aff1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "import databricks.sdk\n",
    "from databricks.sdk.service.workspace import ImportFormat\n",
    "import nbformat\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee040399-add3-44b2-ae01-f0f9f5bae0ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "candidate_dict = [\n",
    "  (\"X\",\"/Workspace/Users/vibhor.nigam@databricks.com/interview-scripts/interview-grading/example-notebooks-ml/04-Machine-Learning-X\")\n",
    "]\n",
    "\n",
    "human_graded_dict = {\n",
    "  \"X\": [5, 30, 25, 5, 0]\n",
    "}\n",
    "w = databricks.sdk.WorkspaceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f5ce6b-7521-41a7-9414-e2eb4ebb1ac1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "module_dict = {\n",
    "  'module_1': dspy.ChainOfThought(MLPrompt1),\n",
    "  'module_2': dspy.ChainOfThought(MLPrompt2),\n",
    "  'module_3': dspy.ChainOfThought(MLPrompt3),\n",
    "  'module_4': dspy.ChainOfThought(MLPrompt4),\n",
    "  'module_5': dspy.ChainOfThought(MLPrompt5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e5a51ac-c3e4-4103-873a-2c6a741d8f7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_code_from_notebooks(workspace_client, notebook_path):\n",
    "   notebook = workspace_client.workspace.export(notebook_path, \n",
    "                                    format=ImportFormat.JUPYTER)\n",
    "   ipynb = base64.decodebytes(notebook.content.encode('ascii')).decode(\"utf-8\")\n",
    "   notebook = nbformat.reads(ipynb, as_version=4)\n",
    "   code_dict = {}\n",
    "   x=0\n",
    "   for cell in notebook.cells:\n",
    "      if cell.cell_type == 'code' or cell.cell_type == 'markdown':\n",
    "         code_dict[x] = cell.source\n",
    "         x+=1\n",
    "   context = ''.join(code_dict.values())\n",
    "   return context\n",
    "# ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11ed57cf-9f00-47cf-871d-f366a246641e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_responses(context, module_dict):\n",
    "  answer_list = []\n",
    "  for k,module in module_dict.items():\n",
    "    response = module(text=context)\n",
    "    response_dict = {\n",
    "      'score': response.score,\n",
    "      'reasoning': response.reasoning,\n",
    "      'code_snippet': response.code_snippet\n",
    "    }\n",
    "    # print(response_dict)\n",
    "    answer_list.append(response_dict)\n",
    "  answer_list_df = pd.DataFrame(answer_list)\n",
    "\n",
    "  return answer_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44acfa44-2c8d-4eae-90d8-d1480cfbed72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(f\" drop table if exists users.abhay_jalisatgi.gen_ai_eval \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cfee88b-76c8-4c9d-8bb3-c8a63639b90a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "error_dict = {}\n",
    "answers_dict = {}\n",
    "for candidate in candidate_dict:\n",
    "  context = get_code_from_notebooks(w, candidate[1])\n",
    "  answers = evaluate_responses(context, module_dict)\n",
    "  answers['candidate'] = candidate[0]\n",
    "  answers['score'] = answers['score'].astype('float64')\n",
    "  # spark.createDataFrame(answers).write.mode(\"append\").saveAsTable(\"users.abhay_jalisatgi.gen_ai_eval\")\n",
    "\n",
    "  human_answers_list = human_graded_dict[candidate[0]]\n",
    "  model_asnwers_list = answers['score'].tolist()\n",
    "  diff = [human_answers_list[i] - model_asnwers_list[i] for i in range(len(human_answers_list))]\n",
    "  \n",
    "  abs_error = np.abs(diff).sum()\n",
    "  inaccurate_predictions = len([x for x in diff if x != 0])\n",
    "\n",
    "  error_dict[candidate[0]] = {'abs_error': abs_error, 'inaccurate_predictions': inaccurate_predictions, 'context': diff}\n",
    "  answers_dict[candidate[0]] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d960767a-63a4-4af1-a45a-931837616103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33c27f61-7a91-4adb-b4b0-bda3faee41fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "answers_dict['X'].display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df2ff886-21b4-43c4-834c-4f7320fd52b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(diff):\n",
    "  unmatched_elements = [i for i in diff if i != 0]\n",
    "  diff_in_score = sum(unmatched_elements)\n",
    "  return diff_in_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87ddfab4-808b-4cf0-87e1-ec7d80adeb39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# human_answer_list_Y = [15,15,15,12,15,25]\n",
    "# model_answer_list_Y = [x.score for x in spark.read.table(\"users.abhay_jalisatgi.gen_ai_eval\").filter(f\"candidate = 'Y'\").select(\"score\").collect()]\n",
    "# diff = [human_answer_list_Y[i] - model_answer_list_Y[i] for i in range(len(human_answer_list_Y))]\n",
    "# print(f\" Human score - Model score : {evaluate_model(diff)}, answers differ for {diff}\")\n",
    "\n",
    "# # Grader Notes for Q4: For Part2, the grouping should not be performed based on date. Partial credit awarded.\n",
    "# # Grading Criteria for Q4: Workload hours each day for the workspaceID (15)- If ordering is missing, deduct 3 points. Each section is 7.5 points."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ML interview notebook grading with GenAI-DSPy",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
